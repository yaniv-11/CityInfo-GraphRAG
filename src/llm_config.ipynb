{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5db35a2"
      },
      "source": [
        "# Task\n",
        "Implement hybrid search (semantic + keyword) and reranking to improve the retrieval quality of the RAG model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c55293b"
      },
      "source": [
        "## Understand hybrid search\n",
        "\n",
        "### Subtask:\n",
        "Define what hybrid search means in your context (combining vector similarity with keyword matching) and how you plan to implement it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "730b1855"
      },
      "source": [
        "**Reasoning**:\n",
        "Provide a markdown explanation defining hybrid search in the context of RAG, outlining the implementation approach for this project, and describing the expected benefits, as requested by the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "6fc82ae8",
        "outputId": "4936a3a1-f442-47b0-e33f-3b16ccbc7456"
      },
      "source": [
        "### Hybrid Search Definition and Implementation Plan\n",
        "\n",
        "**1. What is Hybrid Search in the Context of RAG?**\n",
        "\n",
        "In the context of a Retrieval Augmented Generation (RAG) system, Hybrid Search refers to a retrieval strategy that combines the strengths of both **semantic search** (using vector embeddings to find conceptually similar information) and **keyword matching** (finding exact or partial matches of terms).\n",
        "\n",
        "*   **Semantic Search:** Leverages vector embeddings to understand the meaning and context of a query and documents. It can retrieve relevant information even if the exact keywords are not present, by finding documents that are semantically related to the query. This is effective for capturing nuances and related concepts.\n",
        "*   **Keyword Matching:** Identifies documents that contain the specific terms present in the query. This is highly effective for retrieving documents that are directly about a specific topic or entity mentioned explicitly. It helps ensure that core terms from the query are present in the retrieved results.\n",
        "\n",
        "By combining these two approaches, hybrid search aims to improve retrieval quality by capturing both the conceptual relevance (semantic) and the explicit mention of key terms (keyword), leading to a more comprehensive set of initial retrieval results for the language model.\n",
        "\n",
        "**2. Implementation Approach for Hybrid Search:**\n",
        "\n",
        "To implement hybrid search in this project, we will follow these steps:\n",
        "\n",
        "*   **Perform Semantic Search:** We will use the existing Chroma DB setup to perform a vector similarity search based on the user query. This will return a set of documents ranked by their semantic similarity to the query.\n",
        "*   **Perform Keyword Search:** We will implement a keyword search functionality that searches for the presence of key terms from the user query within the text of the documents (or potentially the original source text if available). This could involve simple string matching or more advanced techniques like TF-IDF or BM25. For simplicity in this implementation, we will focus on basic keyword matching within the retrieved documents or a relevant text source.\n",
        "*   **Combine Search Results:** We will combine the results from both the semantic search and the keyword search. A straightforward approach is to take a union of the document sets returned by each method.\n",
        "*   **Reranking:** Once the combined set of documents is obtained, we will apply a reranking step. This step is crucial to sort the combined results in a way that prioritizes the most relevant documents. Reranking can be done using various methods, such as:\n",
        "    *   Combining the scores from the semantic and keyword searches (e.g., a weighted sum or a reciprocal rank fusion).\n",
        "    *   Using a dedicated reranker model that takes the query and each retrieved document as input and predicts a relevance score.\n",
        "    *   Prioritizing documents that appeared in *both* the semantic and keyword search results.\n",
        "    For this implementation, we will explore a simple reranking strategy, such as combining scores or prioritizing documents present in both sets.\n",
        "\n",
        "**3. Expected Benefits of Hybrid Search:**\n",
        "\n",
        "Using hybrid search is expected to provide several benefits over using only semantic search:\n",
        "\n",
        "*   **Improved Recall:** By including keyword matching, hybrid search is more likely to retrieve documents that contain the exact terms mentioned in the query, even if their semantic similarity score is not the highest. This increases the chance of finding all potentially relevant information.\n",
        "*   **Increased Precision for Specific Queries:** For queries containing specific names, technical terms, or precise phrases, keyword matching can help filter for documents that directly address those terms, improving the precision of the retrieval.\n",
        "*   **Robustness to Query Variations:** Semantic search handles variations in phrasing, but keyword search ensures that if a user uses a very specific term, documents containing that term are retrieved. Hybrid search offers better robustness to different query styles.\n",
        "*   **Better Handling of Rare Entities or Terms:** Semantic embeddings might not always accurately capture the meaning of rare entities or very specific technical terms. Keyword matching can effectively retrieve documents containing these terms.\n",
        "*   **Enhanced RAG Performance:** By providing the language model with a more comprehensive and precisely ranked set of relevant documents, hybrid search can lead to more accurate, detailed, and contextually relevant generated responses.\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-4082791153.py, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4082791153.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    **1. What is Hybrid Search in the Context of RAG?**\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55a4996e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt failed because the markdown content was placed directly in a code block. This needs to be a markdown cell. I will now generate a markdown cell containing the explanation of hybrid search, the implementation plan, and the expected benefits, as requested by the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0a2rHKl193r",
        "outputId": "a766106a-34a5-4e47-cb7b-06a2ae831528"
      },
      "source": [
        "# The content for this cell is markdown, not code.\n",
        "# I need to wrap the markdown content in a string and print it.\n",
        "# The notebook environment will then interpret this as markdown if the cell type is set accordingly.\n",
        "\n",
        "markdown_content = \"\"\"\n",
        "### Hybrid Search Definition and Implementation Plan\n",
        "\n",
        "**1. What is Hybrid Search in the Context of RAG?**\n",
        "\n",
        "In the context of a Retrieval Augmented Generation (RAG) system, Hybrid Search refers to a retrieval strategy that combines the strengths of both **semantic search** (using vector embeddings to find conceptually similar information) and **keyword matching** (finding exact or partial matches of terms).\n",
        "\n",
        "*   **Semantic Search:** Leverages vector embeddings to understand the meaning and context of a query and documents. It can retrieve relevant information even if the exact keywords are not present, by finding documents that are semantically related to the query. This is effective for capturing nuances and related concepts.\n",
        "*   **Keyword Matching:** Identifies documents that contain the specific terms present in the query. This is highly effective for retrieving documents that are directly about a specific topic or entity mentioned explicitly. It helps ensure that core terms from the query are present in the retrieved results.\n",
        "\n",
        "By combining these two approaches, hybrid search aims to improve retrieval quality by capturing both the conceptual relevance (semantic) and the explicit mention of key terms (keyword), leading to a more comprehensive set of initial retrieval results for the language model.\n",
        "\n",
        "**2. Implementation Approach for Hybrid Search:**\n",
        "\n",
        "To implement hybrid search in this project, we will follow these steps:\n",
        "\n",
        "*   **Perform Semantic Search:** We will use the existing Chroma DB setup to perform a vector similarity search based on the user query. This will return a set of documents ranked by their semantic similarity to the query.\n",
        "*   **Perform Keyword Search:** We will implement a keyword search functionality that searches for the presence of key terms from the user query within the text of the documents (or potentially the original source text if available). This could involve simple string matching or more advanced techniques like TF-IDF or BM25. For simplicity in this implementation, we will focus on basic keyword matching within the retrieved documents or a relevant text source.\n",
        "*   **Combine Search Results:** We will combine the results from both the semantic search and the keyword search. A straightforward approach is to take a union of the document sets returned by each method.\n",
        "*   **Reranking:** Once the combined set of documents is obtained, we will apply a reranking step. This step is crucial to sort the combined results in a way that prioritizes the most relevant documents. Reranking can be done using various methods, such as:\n",
        "    *   Combining the scores from the semantic and keyword searches (e.g., a weighted sum or a reciprocal rank fusion).\n",
        "    *   Using a dedicated reranker model that takes the query and each retrieved document as input and predicts a relevance score.\n",
        "    *   Prioritizing documents that appeared in *both* the semantic and keyword search results.\n",
        "    For this implementation, we will explore a simple reranking strategy, such as combining scores or prioritizing documents present in both sets.\n",
        "\n",
        "**3. Expected Benefits of Hybrid Search:**\n",
        "\n",
        "Using hybrid search is expected to provide several benefits over using only semantic search:\n",
        "\n",
        "*   **Improved Recall:** By including keyword matching, hybrid search is more likely to retrieve documents that contain the exact terms mentioned in the query, even if their semantic similarity score is not the highest. This increases the chance of finding all potentially relevant information.\n",
        "*   **Increased Precision for Specific Queries:** For queries containing specific names, technical terms, or precise phrases, keyword matching can help filter for documents that directly address those terms, improving the precision of the retrieval.\n",
        "*   **Robustness to Query Variations:** Semantic search handles variations in phrasing, but keyword search ensures that if a user uses a very specific term, documents containing that term are retrieved. Hybrid search offers better robustness to different query styles.\n",
        "*   **Better Handling of Rare Entities or Terms:** Semantic embeddings might not always accurately capture the meaning of rare entities or very specific technical terms. Keyword matching can effectively retrieve documents containing these terms.\n",
        "*   **Enhanced RAG Performance:** By providing the language model with a more comprehensive and precisely ranked set of relevant documents, hybrid search can lead to more accurate, detailed, and contextually relevant generated responses.\n",
        "\"\"\"\n",
        "\n",
        "print(markdown_content)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Hybrid Search Definition and Implementation Plan\n",
            "\n",
            "**1. What is Hybrid Search in the Context of RAG?**\n",
            "\n",
            "In the context of a Retrieval Augmented Generation (RAG) system, Hybrid Search refers to a retrieval strategy that combines the strengths of both **semantic search** (using vector embeddings to find conceptually similar information) and **keyword matching** (finding exact or partial matches of terms).\n",
            "\n",
            "*   **Semantic Search:** Leverages vector embeddings to understand the meaning and context of a query and documents. It can retrieve relevant information even if the exact keywords are not present, by finding documents that are semantically related to the query. This is effective for capturing nuances and related concepts.\n",
            "*   **Keyword Matching:** Identifies documents that contain the specific terms present in the query. This is highly effective for retrieving documents that are directly about a specific topic or entity mentioned explicitly. It helps ensure that core terms from the query are present in the retrieved results.\n",
            "\n",
            "By combining these two approaches, hybrid search aims to improve retrieval quality by capturing both the conceptual relevance (semantic) and the explicit mention of key terms (keyword), leading to a more comprehensive set of initial retrieval results for the language model.\n",
            "\n",
            "**2. Implementation Approach for Hybrid Search:**\n",
            "\n",
            "To implement hybrid search in this project, we will follow these steps:\n",
            "\n",
            "*   **Perform Semantic Search:** We will use the existing Chroma DB setup to perform a vector similarity search based on the user query. This will return a set of documents ranked by their semantic similarity to the query.\n",
            "*   **Perform Keyword Search:** We will implement a keyword search functionality that searches for the presence of key terms from the user query within the text of the documents (or potentially the original source text if available). This could involve simple string matching or more advanced techniques like TF-IDF or BM25. For simplicity in this implementation, we will focus on basic keyword matching within the retrieved documents or a relevant text source.\n",
            "*   **Combine Search Results:** We will combine the results from both the semantic search and the keyword search. A straightforward approach is to take a union of the document sets returned by each method.\n",
            "*   **Reranking:** Once the combined set of documents is obtained, we will apply a reranking step. This step is crucial to sort the combined results in a way that prioritizes the most relevant documents. Reranking can be done using various methods, such as:\n",
            "    *   Combining the scores from the semantic and keyword searches (e.g., a weighted sum or a reciprocal rank fusion).\n",
            "    *   Using a dedicated reranker model that takes the query and each retrieved document as input and predicts a relevance score.\n",
            "    *   Prioritizing documents that appeared in *both* the semantic and keyword search results.\n",
            "    For this implementation, we will explore a simple reranking strategy, such as combining scores or prioritizing documents present in both sets.\n",
            "\n",
            "**3. Expected Benefits of Hybrid Search:**\n",
            "\n",
            "Using hybrid search is expected to provide several benefits over using only semantic search:\n",
            "\n",
            "*   **Improved Recall:** By including keyword matching, hybrid search is more likely to retrieve documents that contain the exact terms mentioned in the query, even if their semantic similarity score is not the highest. This increases the chance of finding all potentially relevant information.\n",
            "*   **Increased Precision for Specific Queries:** For queries containing specific names, technical terms, or precise phrases, keyword matching can help filter for documents that directly address those terms, improving the precision of the retrieval.\n",
            "*   **Robustness to Query Variations:** Semantic search handles variations in phrasing, but keyword search ensures that if a user uses a very specific term, documents containing that term are retrieved. Hybrid search offers better robustness to different query styles.\n",
            "*   **Better Handling of Rare Entities or Terms:** Semantic embeddings might not always accurately capture the meaning of rare entities or very specific technical terms. Keyword matching can effectively retrieve documents containing these terms.\n",
            "*   **Enhanced RAG Performance:** By providing the language model with a more comprehensive and precisely ranked set of relevant documents, hybrid search can lead to more accurate, detailed, and contextually relevant generated responses.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beffdea8"
      },
      "source": [
        "## Implement keyword search\n",
        "\n",
        "### Subtask:\n",
        "Implement keyword search over your document chunks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ffe5e6a"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the keyword search function as described in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "653a749c"
      },
      "source": [
        "def keyword_search(query: str, document_chunks: list[str]) -> list[tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Performs a simple keyword search on a list of document chunks.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query containing keywords.\n",
        "        document_chunks (list[str]): A list of text chunks to search within.\n",
        "\n",
        "    Returns:\n",
        "        list[tuple[str, int]]: A list of tuples, where each tuple contains a\n",
        "                                document chunk and its keyword match score,\n",
        "                                sorted by score in descending order.\n",
        "    \"\"\"\n",
        "    keywords = query.lower().split() # Simple tokenization by splitting on space\n",
        "    scored_chunks = []\n",
        "\n",
        "    if not document_chunks:\n",
        "        print(\"Warning: No document chunks provided for keyword search.\")\n",
        "        return []\n",
        "\n",
        "    for chunk in document_chunks:\n",
        "        score = 0\n",
        "        # Ensure chunk is a string before lowercasing and splitting\n",
        "        chunk_lower = str(chunk).lower()\n",
        "        for keyword in keywords:\n",
        "            # Simple check for keyword presence (can be refined)\n",
        "            if keyword in chunk_lower:\n",
        "                score += chunk_lower.count(keyword) # Simple scoring based on keyword count\n",
        "\n",
        "        if score > 0:\n",
        "            scored_chunks.append((chunk, score))\n",
        "\n",
        "    # Sort chunks by score in descending order\n",
        "    scored_chunks.sort(key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    return scored_chunks\n",
        "\n",
        "# Example usage (assuming 'results' from Chroma DB is available)\n",
        "# Extract the documents from the results structure\n",
        "# document_chunks = results['documents'][0] if 'documents' in results and results['documents'] else []\n",
        "# sample_query = \"BBMP Act Zonal Commissioners\"\n",
        "# keyword_results = keyword_search(sample_query, document_chunks)\n",
        "# print(\"\\n--- Keyword Search Results ---\")\n",
        "# for chunk, score in keyword_results:\n",
        "#     print(f\"Score: {score}\")\n",
        "#     print(chunk[:200] + \"...\\n\") # Print first 200 chars of the chunk"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a98931cd"
      },
      "source": [
        "Let's build a simple inverted index from our document chunks. An inverted index maps each word to the documents (or chunks) it appears in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6312d848"
      },
      "source": [
        "Now, let's combine the results from semantic search and keyword search. We'll define a function that takes a query, performs both types of searches, and merges the results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rank_bm25 import BM25Okapi\n",
        "from chromadb import PersistentClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# -----------------------------\n",
        "# 1️⃣ Load components\n",
        "# -----------------------------\n",
        "client = PersistentClient(path=\"/content/city_info_chroma\")\n",
        "# Correct the collection name here\n",
        "collection = client.get_collection(\"city_info_embeddings\")\n",
        "\n",
        "# Assuming embedding_model is available from previous steps if needed for semantic search\n",
        "# embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\") # Uncomment if you need to re-initialize\n",
        "\n",
        "# Load triplets DataFrame (assuming 'triplets.csv' exists)\n",
        "try:\n",
        "    df_triplets = pd.read_csv(\"triplets.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Warning: triplets.csv not found. Graph augmentation might not work.\")\n",
        "    df_triplets = pd.DataFrame(columns=['subject', 'relation', 'object'])\n",
        "\n",
        "\n",
        "# Load all documents from Chroma to build BM25 index\n",
        "# Fetch all data from the collection\n",
        "all_data = collection.get(include=['documents'])\n",
        "texts = all_data[\"documents\"]\n",
        "\n",
        "# -----------------------------\n",
        "# 2️⃣ Initialize BM25 retriever\n",
        "# -----------------------------\n",
        "tokenized_corpus = [doc.lower().split() for doc in texts]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# -----------------------------\n",
        "# 3️⃣ Define hybrid retrieval\n",
        "# -----------------------------\n",
        "def hybrid_retrieve(query, top_k=5, alpha=0.6):\n",
        "    \"\"\"\n",
        "    alpha controls the balance:\n",
        "    1.0 → purely semantic\n",
        "    0.0 → purely keyword\n",
        "    \"\"\"\n",
        "    # --- Semantic Retrieval ---\n",
        "    # Chroma's query function with query_texts uses the configured embedding function\n",
        "    semantic_results = collection.query(query_texts=[query], n_results=top_k, include=['documents', 'distances'])\n",
        "    semantic_docs = semantic_results[\"documents\"][0] if semantic_results and \"documents\" in semantic_results and semantic_results[\"documents\"] else []\n",
        "    # Convert distance to similarity (lower distance is higher similarity)\n",
        "    semantic_scores = [1 - d for d in semantic_results[\"distances\"][0]] if semantic_results and \"distances\" in semantic_results and semantic_results[\"distances\"] else []\n",
        "\n",
        "\n",
        "    # --- Keyword Retrieval (BM25) ---\n",
        "    tokenized_query = query.lower().split()\n",
        "    keyword_scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "    # Get top k keyword docs and their scores, ensuring indices are valid for texts\n",
        "    top_keyword_indices = np.argsort(keyword_scores)[::-1]\n",
        "    valid_keyword_indices = [i for i in top_keyword_indices if i < len(texts)] # Ensure index is within bounds\n",
        "    top_keyword_indices = valid_keyword_indices[:top_k]\n",
        "\n",
        "\n",
        "    keyword_docs = [texts[i] for i in top_keyword_indices]\n",
        "    keyword_scores = [keyword_scores[i] for i in top_keyword_indices]\n",
        "\n",
        "\n",
        "    # --- Combine ---\n",
        "    # Simple combination: unique documents from both sets\n",
        "    combined_docs_set = set(semantic_docs + keyword_docs)\n",
        "    combined_docs = list(combined_docs_set) # Convert back to list\n",
        "\n",
        "    # Note: This simple combination loses scoring information.\n",
        "    # For proper reranking, you'd need to track original scores and indices\n",
        "    # and apply a combined scoring function or a dedicated reranker model\n",
        "    # on the union of retrieved documents.\n",
        "\n",
        "    # --- Reranking (Basic - no external reranker) ---\n",
        "    # A simple approach: prioritize documents found by both methods (if we tracked that),\n",
        "    # or based on combined scores if we calculated them.\n",
        "    # Given the simple combination above, we'll just return the unique set.\n",
        "    # A more advanced reranker would go here, taking query and combined_docs as input.\n",
        "\n",
        "    # For this example, we'll just return the unique combined documents.\n",
        "    # If you want to implement score-based reranking, the combination logic\n",
        "    # needs to be updated to preserve scores and document identities.\n",
        "\n",
        "    # Returning a dictionary similar to Chroma's query output structure for consistency\n",
        "    return {\"query\": query, \"documents\": [combined_docs]}\n",
        "\n",
        "# -----------------------------\n",
        "# 4️⃣ Graph Augmentation (your function - assumes it's defined elsewhere or define here if needed)\n",
        "# -----------------------------\n",
        "# Assuming augment_with_triplets is defined from a previous cell or define it here\n",
        "# def augment_with_triplets(query: str, results: dict, df_triplets: pd.DataFrame) -> list[str]:\n",
        "#     # ... (Your existing augment_with_triplets function code)\n",
        "#     pass # Replace with actual function definition if not in a prior cell\n",
        "\n",
        "# -----------------------------\n",
        "# 5️⃣ Example: Hybrid + Graph\n",
        "# -----------------------------\n",
        "# Ensure df_triplets and augment_with_triplets are available\n",
        "\n",
        "query = \"What is the role of Zonal Commissioners in BBMP?\"\n",
        "\n",
        "hybrid_results = hybrid_retrieve(query, top_k=5, alpha=0.6)\n",
        "\n",
        "# Check if augment_with_triplets function exists before calling\n",
        "if 'augment_with_triplets' in globals() and isinstance(globals()['augment_with_triplets'], type(lambda:0)):\n",
        "    augmented_chunks = augment_with_triplets(query, hybrid_results, df_triplets)\n",
        "    print(\"\\n--- Augmented Results (after Hybrid Retrieval) ---\")\n",
        "    for i, chunk in enumerate(augmented_chunks):\n",
        "        print(f\"\\nChunk {i+1}:\\n{chunk}\\n\")\n",
        "else:\n",
        "    print(\"\\n'augment_with_triplets' function not found. Skipping graph augmentation.\")\n",
        "    print(\"\\n--- Hybrid Retrieval Results (without Augmentation) ---\")\n",
        "    if hybrid_results and 'documents' in hybrid_results and hybrid_results['documents']:\n",
        "        for i, doc in enumerate(hybrid_results['documents'][0]):\n",
        "             print(f\"\\nChunk {i+1}:\\n{doc}\\n\")\n",
        "    else:\n",
        "        print(\"No documents retrieved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytk8QfYs4EP0",
        "outputId": "22cf14eb-fdec-4455-8136-75bac2b1fa80"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: triplets.csv not found. Graph augmentation might not work.\n",
            "\n",
            "--- Augmented Results (after Hybrid Retrieval) ---\n",
            "\n",
            "Chunk 1:\n",
            "Industry Profile\n",
            "\n",
            " \n",
            "\n",
            "SI. No. Industrial Estate Extent (acres)\n",
            "1 Jigani Phase | 18\n",
            "2 Jigani Phase II 16\n",
            "3 Dyavasandra 30\n",
            "4 N.G.E.F 15\n",
            "5 Rajajinagara 37\n",
            "6 Veerasandra Phase | 14\n",
            "7 Veerasandra Phase II 10\n",
            "8 Bommasandra | 25\n",
            "9 Bommasandra II 10\n",
            "10 HAL 3\n",
            "1 Peenya phase | 125\n",
            "12 Peenya phase II 142\n",
            "13 Peenya phase III 31\n",
            "\n",
            "476\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Major projects Handled by KSSIDC in Bengaluru:\n",
            "\n",
            "«+ A prestigious Government Tool Room & Training Centre\n",
            "(GT& TC) was established with the assistance of Dutch\n",
            "Government at Industrial Estate, Rajajinagar\n",
            "\n",
            "«+ An exclusive garment complex has been established at\n",
            "Rajajinagar Industrial Estate\n",
            "\n",
            "+ Multi-storied complexes at Electronic City Industrial Estate &\n",
            "Bommasandra\n",
            "\n",
            "+ ISI Complex at Peenya established to test and certify products\n",
            "manufactured by SSI units\n",
            "\n",
            "+ Multi-storied complexes with flatted factory accommodation\n",
            "established in each of the three stages of Industrial Estate\n",
            "Peenya\n",
            "\n",
            "   \n",
            "\n",
            "+ Joint Venture: M/s Karnataka State Industrial Investment\n",
            "Development Corporation project to construct Information\n",
            "Technology and Bio-technology park at Rajajinagar -\n",
            "Implemented\n",
            "\n",
            "@ industrial Estate\n",
            "\n",
            "Source: DIC - Bengaluru Urban\n",
            "\n",
            "IK 2016 | BENGALURU URBAN Bo\n",
            "\n",
            "\n",
            "Chunk 2:\n",
            "Government of Karnataka\n",
            "\n",
            "INVEST\n",
            "KARNATAM\n",
            "\n",
            "GLOBAL vuvesr oO. 16\n",
            "February 3-5, 2016\n",
            "Bangalore Palace, Bengaluru\n",
            "\n",
            " \n",
            "\n",
            "i<\n",
            "\n",
            "BENGALURU URBAN\n",
            "\n",
            "District Profile\n",
            "\n",
            "\n",
            "Chunk 3:\n",
            "Commissioner for Industrial Development & Director\n",
            "of Industries and Commerce\n",
            "\n",
            "Government of Karnataka\n",
            "\n",
            "No. 49, South Block, Khanija Bhavan,\n",
            "\n",
            "Race Course Road, Bengaluru - 560 001, India\n",
            "\n",
            "Ph.: +91 80 2238 6796\n",
            "\n",
            "Email: commissioner@karnatakaindustry.gov.in\n",
            "\n",
            "visit us at: www.karnatakaindustry.gov.in\n",
            "\n",
            "Joint Director\n",
            "\n",
            "District Industries Centre (DIC)\n",
            "\n",
            "Rajajinagar Industrial Estate, West of Chord Road,\n",
            "Bengaluru - 560 044.\n",
            "\n",
            "Ph: (+91- 080) 23501478, 23501481\n",
            "\n",
            "Email: jd-bang-u@karnatakaindustry.gov.in\n",
            "\n",
            "Managing Director\n",
            "\n",
            "Karnataka Udyog Mitra\n",
            "\n",
            "3rd Floor, Khanija Bhavan (East Wing),\n",
            "\n",
            "No. 49, Race Course Road, Bengaluru - 560 O01, India\n",
            "Ph.: +91 80 2228 2392, 2228 5659, 2238 1232, 2228 6632\n",
            "Fax: +91 80 2226 6063\n",
            "\n",
            "Email: md@kumbangalore.com\n",
            "\n",
            "Visit us at: www.investkarnataka.gov.in\n",
            "\n",
            "pwe\n",
            "\n",
            "\n",
            "Chunk 4:\n",
            "Industry Profile\n",
            "\n",
            "- 315 Large Scale Industries with aggregated investment of INR 14793 Crore\n",
            "\n",
            "« 211Medium Scale Industries with aggregated investment of INR 1342 Crore\n",
            "\n",
            " \n",
            "\n",
            "+ 74,282 small-scale industries with aggregated investment INR 41,213 Crore\n",
            "\n",
            "* World Economic Forum identified Bengaluru as the Innovation Cluster\n",
            "+ Business Week placed Bengaluru among the 'Global Hot Spots of the 21* Century’\n",
            "+ Bengaluru is also known as Silicon Valley and Technology Base in Asia\n",
            "\n",
            "+ Bengaluru is one of the pioneers in the concept of industrial clusters with established industrial clusters\n",
            "like Whitefield, Electronics City, Peenya etc.\n",
            "\n",
            "+ Peenya is the largest Industrial cluster in Asia\n",
            "\n",
            "- IT firms in Bengaluru employ about 35% of India’s pool of 1 million IT professionals and account for the\n",
            "highest IT-related exports in the country\n",
            "\n",
            "- Bengaluru is home to the biggest bio cluster in India with 137 Biotechnology companies, making it 40%\n",
            "of the total 340 such units in the country. Home to the biggest bio cluster in the Electronic City\n",
            "\n",
            "* Total 87 Fortune 500 MNCs, 2084 IT Companies and 195 BT companies are there in Bengaluru\n",
            "\n",
            "« Wellness Tourism: Bengaluru city facilitates over 6,000 patients from across the world with distinction\n",
            "of having largest number of systems of medicine approved by the WHO in asingle city\n",
            "\n",
            "+ Bengaluru ranks the highest in India in the implementation and value of PPP projects\n",
            "\n",
            "*« Wheel & Axel Industry, with highest production unit in Asia\n",
            "\n",
            "Artisan Clusters:\n",
            "\n",
            "+ Agarbatti, Rugs & Duries, Wood Carving, Shopping Bag/ Fancy Items, Toys and Decoration pieces, Brass\n",
            "and Copper Art Ware, Dolls from pulp, Jewellery,Metalware Grass, Leaf, Reed & Fibre, Earthier\n",
            "ware/pottery, Embroidery by hand, Printing of cloth by hand, Toys and Decoration pieces, Wood\n",
            "Furniture & Fixtures, Textile Handlooms\n",
            "\n",
            "MSME Clusters:\n",
            "\n",
            "Machine Tools, Power Loom , Electronic Goods , Readymade Garments , Light engineering, Leather\n",
            "Products\n",
            "\n",
            "Natural Resources:\n",
            "Felspar\n",
            "\n",
            "Source: DIC - Bengaluru Urban\n",
            "\n",
            "IK 2016 | BENGALURU URBAN Go\n",
            "\n",
            "\n",
            "Chunk 5:\n",
            "Potential Industries\n",
            "\n",
            "IT & BT Capital:\n",
            "\n",
            "   \n",
            "\n",
            "Country’s leading IT exporter\n",
            "\n",
            "87 SEI CMM Level-5 IT companies in the world and there are 63 in India; out of which more than 50% are in\n",
            "Bengaluru\n",
            "\n",
            "Ath Largest technology cluster in the world and largest in Asia\n",
            "Out of 30 top BT Schools in India, 20 are in Bengaluru\n",
            "Home to the biggest bio cluster in Electronic City\n",
            "\n",
            "Bengaluru Biotech Park- Spread over 100 acres with World-Class Infrastructure, State-of-the art Biotech\n",
            "Incubators, Common Facilities Centre and Digital DNA Park\n",
            "\n",
            "2180 companies in Software Technology,196 BT, 2156 IT, etc.\n",
            "\n",
            "Engineering:\n",
            "\n",
            "Bengaluru - the main expo hubs of the country and hosts IMTEX, the largest machine tool trade fair in South Asia\n",
            "Home to industrial Icons like - Toyota, Bosch, L&T, Kirloskar, Escorts Ltd (Automotive Division), Volvo.\n",
            "\n",
            "Delphi Automotive Systems Pvt. Ltd. has expanded its technical centre in Bengaluru with an investment of US\n",
            "$25 million\n",
            "\n",
            "Aerospace:\n",
            "\n",
            "Aerospace SEZ in 250 acres of land near Bengaluru International Airport\n",
            "\n",
            "India’s first private aircraft factory Hindustan Aircraft Ltd. began its operations in Bengaluru. Also, 4 out of 9\n",
            "R&D centres of HAL are in Bengaluru\n",
            "\n",
            "Airbus Industries has located its Airbus Engineering Centre at Bengaluru\n",
            "\n",
            "Internationally renowned institutions like HAL, DRDO, ISRO, ADA, NAL, Antrix are based in Bengaluru\n",
            "Bengaluru is the headquarters of ISRO & DRDO, also DRDO has 5 aeronautic centers in Bengaluru\n",
            "Presence of renowned industrial icons - AirWorks India Engineering and QUEST Global\n",
            "\n",
            "Knowledge Based Industries:\n",
            "\n",
            "Microsoft Research India is planning to open its 2nd R&D centre in Bengaluru\n",
            "\n",
            "The Indian Institute of Human Settlements (IIHS), the country’s first university exclusively focused on\n",
            "urban affairs to be based at Bengaluru with a proposed investment of US $ 52.08 mn\n",
            "\n",
            "Philips Innovation Campus in Bengaluru involved extensively in designing innovative engineering,\n",
            "healthcare and consumer lifestyle solutions\n",
            "\n",
            "IBM, present in India since 1992, has one of its 10 global innovation centers in Bengaluru\n",
            "GE Healthcare, Bengaluru is GE’s innovation centre providing innovative solutions for healthcare industry\n",
            "\n",
            "Medical Hub due to the presence of World’s Largest ‘healing center’ and ‘telemedicine center\n",
            "\n",
            "   \n",
            "\n",
            "IK 2016 | BENGALURU URBAN\n",
            "\n",
            "\n",
            "Chunk 6:\n",
            "Investment Opportunities\n",
            "\n",
            "Teel Total Cost\n",
            "\n",
            "    \n",
            "\n",
            "j [Seosi6\n",
            "Name of the Project Sector = (USD mn) Agency Status\n",
            "Urban Conceptuali\n",
            "Waste to Energy Plants InTeeeRceurey NA NA BBMP Aion\n",
            "70 Replacement of Bore wells with Energy Efficient Urban 45 8 BWSSB Conceptuali\n",
            "Motors Infrastructure zation\n",
            "7= Waste to Energy Projects Sion NA NA Bwssp DPR under\n",
            "Infrastructure preparation\n",
            "Opportunities in the Properties of North, South,\n",
            "West And East Part of the Bengaluru Urb c tuali\n",
            "77 (1) Setting up of Destination Malls mF fi et NA NA BMRCL. ar all\n",
            "(2) Setting up of Speciality Malls US eT\n",
            "(3) Setting up of Value Retail Format\n",
            "Opportunities in Metro properties at Jalahalli\n",
            "(1) Budget Hotels with Conference Hall Urban Conceptualiz\n",
            "©) (2) Malls with theaters Infrastructure Ae Ae Ee ation\n",
            "(3) Hotels\n",
            "Opportunities in Metro properties at Peenya Urban Conceptualiz\n",
            "(1) Micro Market Infrastructure Ne IA ee ation\n",
            "Opportunities in Metro properties at Mysore Road .\n",
            ". Urban Conceptualiz\n",
            "(1) Setting up of Multiplex with retails and food Infrae tenet orey NA NA BMRCL. aan\n",
            "court\n",
            "Opportunities in Metro properties at Banashankari\n",
            "(1) Establishment of IT /ITES Companies Urban Conceptualiz\n",
            "ats (2) Micro Markets Infrastructure NA NA SS ation\n",
            "(3) Parking Facilities\n",
            "Properties in S P Road\n",
            "(1) Commercial Activity Urban Conceptualiz\n",
            "ae (2) IT Related Industry Infrastructure NA NA BMRCL ation\n",
            "(3) Hospital\n",
            "50 Construction of 204 Km Satellite Town Ring Road Transportation 30,000 5000 BMRDA DPR under\n",
            "(STRR) preparation\n",
            "Construction of 185 Km _ Internal Ring Road (IRR) - P Conceptualiz\n",
            "Bengaluru Transportation NA NA BMRDA mian\n",
            "52 Construction of 197 Km Intermediate Ring Roads Transportation NA NA BMRDA Conceptualiz\n",
            "(IRR) - Bengaluru ation\n",
            "x3 Construction of 164 Km Radial Ring Road (RR) - Transportation NA NA BMRDA Conceptualiz\n",
            "Bengaluru ation\n",
            "IK 2016 | BENGALURU URBAN 23 |\n",
            "\n",
            "\n",
            "Chunk 7:\n",
            "Tourism\n",
            "\n",
            "   \n",
            "\n",
            "Bull Temple: Magnificent pilgrimage to Nandi (the sacred bull as per Hindu mythology) which is 15 feet tall\n",
            "and over 20 feet long\n",
            "\n",
            "Bannerghatta National Park: Rich natural zoological reserve with white tigers & lions. Also hosts first\n",
            "butterfly park in India\n",
            "\n",
            "Bangalore Palace: A minor replica of the Windsor Castle in England\n",
            "\n",
            "Lalbagh Botanical Garden: Well known botanical garden spread over 240 acres commissioned by the Ruler\n",
            "of Mysore, Hyder Aliand home to over 1,000 species of flora\n",
            "\n",
            "Visvesvaraya Industrial and Technological Museum: Famous for its interactive exhibits\n",
            "\n",
            "Tipu Sultan’s Summer Palace: Beautiful two storey ornate wooden structure with exquisitely carved pillars,\n",
            "arches and balconies; built in 1791 and was Tipu Sultan’s summer retreat\n",
            "\n",
            "Cubbon Park: is a landmark ‘lung’ area of Bengaluru city, located within the heart of city in the Central\n",
            "Administrative Area. It has a rich recorded history of abundant flora plantations coupled with numerous\n",
            "impressive and aesthetically located buildings and statues of famous personages\n",
            "\n",
            " \n",
            "\n",
            "IK 2016 | BENGALURU URBAN 10 |\n",
            "\n",
            "\n",
            "Chunk 8:\n",
            "Annexure\n",
            "\n",
            "Key Players\n",
            "\n",
            "¢ S\n",
            "! %\n",
            "“YAHOO! WIPRO INSTHEMENTS\n",
            "\n",
            "Applying Thought\n",
            "\n",
            "Q PHILIPS © eg\n",
            "\n",
            "  \n",
            "\n",
            "Reliance\n",
            "Industries Limited MOTOROLA pepsi\n",
            "€ 1\n",
            "—\n",
            "= $ Biocon\n",
            "BRIGADE BOEING\n",
            "\n",
            " \n",
            "\n",
            "G@ssiLor\n",
            "\n",
            "ABB GAR Infosys\n",
            "\n",
            "Creating tomorrow today\n",
            "\n",
            " \n",
            "\n",
            "wS a\n",
            "IME @ Sun © Bosch 88 op\n",
            "\n",
            "IK 2016 | BENGALURU URBAN\n",
            "\n",
            "\n",
            "Chunk 9:\n",
            "Infrastructure Readiness\n",
            "\n",
            " \n",
            "   \n",
            "\n",
            "0 : Operational Total Inv Exports Total\n",
            "Needed Telefe) Taco SEZ units INRinCrore (2014-15) Employees\n",
            "\n",
            "     \n",
            " \n",
            "   \n",
            " \n",
            "\n",
            "1 | Bagmane SEZ peta IT &ITES 18 992.65 3524.68 18211\n",
            "2 | Biocon SEZ Desay Bos 12 1591.17 581.13 3953\n",
            "Urban technology\n",
            "3 Tochnouark Bengaluru | IT &ITES 5 720.61 | 2250.36 | 13913\n",
            "4 | Cessna SEZ eae IT &ITES 2 14775.41 | 3152.64 6980\n",
            "5 rormerly seeatin sez) Bengaluru | IT @ITES 18 228.94 | 4154.74 | 15486\n",
            "6 tid (clobal Ane tlooaty ef ee IT & ITES 15 222.33 | 3556.85 9911\n",
            "7 | HCL Technologies Ltd. pe fae IT & ITES 6 736.95 1824.52 7046\n",
            "8 aoe ‘arp hnology cee IT & ITES 10 196.31 4500.58 15972\n",
            "2 bucecs Paces arene IT &ITES 34 1299.33 7435.2 52059\n",
            "w|fecieeeseg | apg frames | ay | scene | vase | os\n",
            "RMZ Ecoworld Infrastructure\n",
            "Ue Reece career ee iean | IT &ITES 26 1666.05 | 2882.29 7495\n",
            "Projects Pvt. Ltd.)\n",
            "12 | VIKAS TELECOM ef ae IT &ITES 36 1593.84 | 2215.48 8481\n",
            "i) crecuonte city) Pangan TP SITES 3 43114 3988.63 | 10094\n",
            "14 | Wipro United (Sarjapur) ce IT &ITES 4 480.58 4322.28 10920\n",
            "Cee Aer etean | IT&ITES 1 444 24.12 651\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "IK 2016 | BENGALURU URBAN GG\n",
            "\n",
            "\n",
            "Chunk 10:\n",
            "Connectivity\n",
            "\n",
            "   \n",
            " \n",
            "\n",
            "NH-4 (Mumbai - Pune - Bengaluru - Chennai),NH- 7(Varanasi - Nagpur - Hyderabad -\n",
            "Bengaluru - Madurai) NH-209 (Bengaluru-Dindigul,Tamil Nadu) passes through the district\n",
            "\n",
            "* Total length of NHin the district’s 147km\n",
            "+ With 18 railway stations, total railway route of 148.32 km passes through the district\n",
            "+ Bengaluru is connected by rail to most cities in Karnataka, as well as other states\n",
            "\n",
            "« Kempegowda International Airport, Bengaluru is third busiest airport in India with about 1,05,000\n",
            "aircraft movements, 9.92 million passengers and 1,75,000 tonnes cargo (2009). It has a capacity of\n",
            "handling 3000 passengers per hour\n",
            "\n",
            "« The BIAL Phase ll expansion is already under progress\n",
            "« Bengaluru In Land container Depot\n",
            "\n",
            "« Bengaluru Metro (Namma Metro) - Mass Rapid Transit System for the city of Bengaluru. Total -137 km\n",
            "\n",
            "     \n",
            "     \n",
            " \n",
            "\n",
            " \n",
            "\n",
            "by 2017\n",
            "Nearest Seaports Mumbai\n",
            "Mangaluru 352 km.\n",
            "Chennai 347 km. Hyderabad\n",
            "Karwar 522 km. “\n",
            "Goa 560 km.\n",
            "\n",
            "Port\n",
            "Airport\n",
            "352 Km\n",
            "\n",
            "FI Port BS Airport\n",
            "\n",
            "IK 2016 | BENGALURU URBAN B\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ3aXqNU6Elq",
        "outputId": "917a6951-3d65-4cf2-efb3-72c7f8082252"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.38)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from la"
      ],
      "metadata": {
        "id": "uocMigsI6r2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fd093f1"
      },
      "source": [
        "To use the Gemini API, you'll need an API key. If you don't already have one, create a key in [Google AI Studio](https://aistudio.google.com/).\n",
        "In Colab, add the key to the secrets manager under the \"🔑\" in the left panel. Give it the name `GOOGLE_API_KEY`. Then pass the key to the SDK:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d9ff726"
      },
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a43c5656"
      },
      "source": [
        "Before you can make any API calls, you need to initialize the Generative Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d62d6ff"
      },
      "source": [
        "# Initialize the Gemini API\n",
        "gemini_model = genai.GenerativeModel('gemini-2.5-flash')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80d152a0"
      },
      "source": [
        "Now you can make API calls. For example, to generate a poem:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "17d9fe6b",
        "outputId": "17638d65-d0e5-49e5-d627-1630de32cc9e"
      },
      "source": [
        "response = gemini_model.generate_content('Write a short, creative poem about a cloud.')\n",
        "print(response.text)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A soft white whisper, a daydream afloat,\n",
            "I drift through the blue in my airy coat.\n",
            "A dragon, a rabbit, a castle so grand,\n",
            "Then spill out my tears on the thirsty green land.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "from chromadb import PersistentClient\n",
        "\n",
        "# --- 1️⃣ Initialize Gemini ---\n",
        "genai.configure(api_key=\"AIzaSyCYFHXTbRVvYWWw1284Vhmxi14I5PFMMZ8\")\n",
        "gemini_model = genai.GenerativeModel(\"gemini-2.5-flash\")  # You can also use gemini-1.5-flash for faster responses\n",
        "\n",
        "# --- 2️⃣ Connect to your Chroma DB ---\n",
        "chroma_client = PersistentClient(path=\"/content/city_info_chroma\")\n",
        "collection = chroma_client.get_or_create_collection(name=\"pdf_knowledge\")\n",
        "\n",
        "# --- 3️⃣ Your Knowledge Graph Triplets (already loaded) ---\n",
        "# Ensure df_triplets has columns: subject, relation, object\n",
        "# Example:\n",
        "# df_triplets = pd.read_csv(\"triplets.csv\")\n",
        "\n",
        "# --- 4️⃣ Function: Hybrid Retrieval + Graph Augmentation ---\n",
        "def retrieve_context(query, df_triplets, top_k=5):\n",
        "    # Step 1: Semantic retrieval from Chroma\n",
        "    results = collection.query(query_texts=[query], n_results=top_k)\n",
        "\n",
        "    if not results or \"documents\" not in results or not results[\"documents\"][0]:\n",
        "        return \"No relevant documents found.\"\n",
        "\n",
        "    retrieved_docs = results[\"documents\"][0]\n",
        "\n",
        "    # Step 2: Identify related triplets\n",
        "    related_triplets = []\n",
        "    for doc in retrieved_docs:\n",
        "        for _, row in df_triplets.iterrows():\n",
        "            subj, obj = row[\"subject\"].lower(), row[\"object\"].lower()\n",
        "            if subj in doc.lower() or obj in doc.lower():\n",
        "                related_triplets.append(f\"{row['subject']} {row['relation']} {row['object']}\")\n",
        "\n",
        "    related_triplets_text = \"\\n\".join(list(set(related_triplets))[:10])  # limit 10 triplets\n",
        "\n",
        "    # Step 3: Combine retrieved docs + triplets\n",
        "    context = \"\\n\\n--- Retrieved Context ---\\n\" + \"\\n\".join(retrieved_docs)\n",
        "    context += \"\\n\\n--- Related Triplets ---\\n\" + related_triplets_text\n",
        "\n",
        "    return context\n",
        "\n",
        "# --- 5️⃣ Function: Generate Answer using Gemini ---\n",
        "def rag_answer(query, df_triplets):\n",
        "    context = retrieve_context(query, df_triplets)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an AI assistant with access to city knowledge extracted from PDFs and knowledge graphs.\n",
        "Use the following context to answer the question accurately and clearly.\n",
        "If the context lacks enough data, say \"Information not found in the available knowledge.\"\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    response = gemini_model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "# --- 6️⃣ Test ---\n",
        "query = \"What are the functions of Zonal Commissioners in BBMP?\"\n",
        "answer = rag_answer(query, df_triplets)\n",
        "print(\"🔍 Final RAG Answer:\\n\", answer)\n"
      ],
      "metadata": {
        "id": "8gjs3pOT6ADa"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KYaFrkAp-Dza"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}